<meta charset="UTF-8">
  <meta name="viweport" content="widht=device-width, initial-sacle=1.0">
  <title>page</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0/css/materialize.min.css">
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

  <nav>
  <div class="nav-wrapper blue-grey darken-3">
    <a href="#!" class="brand-logo">GitHub Page</a>
    <ul class="right hide-on-med-and-down">
      <li><a id="Inicio" href="index.html"" class="botones">Inteligencia Artificial</a></li>
      <li><a id="Perceptron" class="botones" href="perceptron.html">Perceptron</a></li>
      <li><a id="Red_nueronal" class="botones" href="red_neuronal.html">Redes Neuronal Simple</a></li>
      <li><a id="multiple" class="botones" href="multiple.html">Red Neuronal Multiple</a></li>
      <li><a id="anexos" class="botones" href="funciones.html">Funciones de Activacion</a></li>
      <li><a id="videos" class="botones" href="#">Videos</a></li>
      <!-- Dropdown Trigger -->
      
    </ul>
  </div>
</nav>

<div  class="perceptron" align="center">
    <div class="row">
    <!--<div class="col s10 m7 center">-->
      <div class="card center">
        <div class="card-image" >
          <!--<img src="C:\Users\Usuario\Desktop\page.github\perce.png"  width="100" height="200">-->
         <!-- <span class="card-title">Card Title</span>-->
        </div>
        <h2>Funciones de Activacion</h2>
        <h4>Que son</h4>
        <div class="card-content">
          <p align="left">En redes computacionales, la Función de Activación de un nodo define la salida de un nodo dada una entrada o un conjunto de entradas. Se podría decir que un circuito estándar de computador se comporta como una red digital de funciones de activación al activarse como "ON" (1) u "OFF" (0), dependiendo de la entrada. Esto es similar al funcionamiento de un Perceptrón en una Red neuronal artificial.

            <br>
          En las redes neuronales inspiradas sobre la biología, la función de activación es usualmente una abstracción representando una tasa de potencial de activación gatillándose en la celda. En su forma simplificada, esta función es binaria, esto es, se activa la neurona o no. La función se ve como {\displaystyle \phi (v_{i})=U(v_{i})}\phi(v_i)=U(v_i), donde {\displaystyle U}U es la función escalón. En este caso, un gran número de neuronas deben ser usadas en computación más allá de la separación lineal de las categorías.

Una función rampa también puede ser usada para reflejar el incremento del potencial de activación que ocurre cuando la entrada se incrementa. La función podría ser de la forma {\displaystyle \phi (v_{i})=\mu v_{i}}\phi(v_i)=\mu v_i, donde {\displaystyle \mu }\mu es la pendiente. Esta función de activación es lineal, y por consiguiente tiene los mismos problemas que la función binaria. En adición, las redes neuronales construidas usando este modelo tienen convergencia inestable porque a la larga, las entradas a la neurona tienden a incrementarse sin límite, esta función no es normalizable.
</p>
<h4>Funcion Sigmoidal</h4>
<img src="C:\Users\Usuario\Desktop\page.github\sigmoide.png" width="600" height="400" class="center">
<p>Muchos procesos naturales y curvas de aprendizaje de sistemas complejos muestran una progresión temporal desde unos niveles bajos al inicio, hasta acercarse a un clímax transcurrido un cierto tiempo; la transición se produce en una región caracterizada por una fuerte aceleración intermedia. La función sigmoide permite describir esta evolución. Su gráfica tiene una típica forma de "S". A menudo la función sigmoide se refiere al caso particular de la función logística</p>
<br>
<p>
  
</p>
<h4>Funcion Tangente Hiperbolica</h4>
<img src="C:\Users\Usuario\Desktop\page.github\tangente.png" width="600" height="400" class="center">
<p>La función tangente hiperbólica transforma los valores introducidos a una escala (-1,1), donde los valores altos tienen de manera asintótica a 1 y los valores muy bajos tienden de manera asintótica a -1.

<br>
Características de la función tangente hiperbólica:
<br>
Muy similar a la signoide
Satura y mata el gradiente.
Lenta convergencia.
Centrada en 0.
Esta acotada entre -1 y 1.
Se utiliza para decidir entre uno opción y la contraria.
Buen desempeño en redes recurrentes.</p>

<h4>Relu</h4>
<img src="C:\Users\Usuario\Desktop\page.github\relu.png" width="600" height="400" class="center">
<p>Activación Sparse – solo se activa si son positivos.
No está acotada.
Se pueden morir demasiadas neuronas.
Se comporta bien con imágenes.
Buen desempeño en redes convolucionales.</p>

<h4></h4>
<p>Activación Sparse – solo se activa si son positivos.
No está acotada.
Se pueden morir demasiadas neuronas.
Se comporta bien con imágenes.
Buen desempeño en redes convolucionales.</p>

        </div>
        <div class="card-action">

          <a href="#">Perceptron</a>
        </div>
      </div>
    </div>
  </div>
  <div>
          
<div>
  <footer class="page-footer blue-grey darken-3"">
          <div class="container ">
            <div class="row">
              <div class="col l6 s12">
                <h5 class="white-text">Inteligencia Artificial- Machine Learning</h5>
                <p class="grey-text text-lighten-4">Inteligencia artificial, Antes Soñada, Para el dia de hoy es una realidad Computada.</p>
              </div>
              <div class="col l4 offset-l2 s12">
                <h5 class="white-text">Links de interes</h5>
                <ul>
                  <li><a class="grey-text text-lighten-3" href="#!">Perceptron</a></li>
                  <li><a class="grey-text text-lighten-3" href="#!">Redes Neuronales Simples</a></li>
                  <li><a class="grey-text text-lighten-3" href="#!">Redes Neuronales Multiples</a></li>
                  <li><a class="grey-text text-lighten-3" href="#!">Funciones de Activacion </a></li>
                </ul>
              </div>
            </div>
          </div>
          
          <div class="footer-copyright">
            <div class="container">
            © 2019 Copyright Ekn Desing
            <p>Elkin Ramirez - Lorena Sanchez - Felipe Marin</p>
            <a class="grey-text text-lighten-4 right" href="#!">Videos</a>
            </div>
          </div>
        </footer>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0/css/materialize.min.css"